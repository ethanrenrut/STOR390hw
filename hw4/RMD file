---
title: "HW 4"
author: "Ethan Turner"
date: "03/06/2024"
output: 
  html_document:
    number_sections: true
---

This homework is designed to give you practice fitting a logistic regression and working with statistical/philosophical measures of fairness.  We will work with the `titanic` dataset which we have previously seen in class in connection to decision trees.  

Below I will preprocess the data precisely as we did in class.  You can simply refer to `data_train` as your training data and `data_test` as your testing data.  




```{r}

#this is all of the preprocessing done for the decision trees lecture.  

path <- 'https://raw.githubusercontent.com/guru99-edu/R-Programming/master/titanic_data.csv'
titanic <-read.csv(path)
head(titanic)

library(dplyr)

#replace ? with NA
replace_question_mark <- function(x) {
  if (is.character(x)) {
    x <- na_if(x, "?")
  }
  return(x)
}

titanic <- titanic %>%
  mutate_all(replace_question_mark)

set.seed(678)
shuffle_index <- sample(1:nrow(titanic))
head(shuffle_index)

titanic <- titanic[shuffle_index, ]
head(titanic)

library(dplyr)
# Drop variables
clean_titanic <- titanic %>%
select(-c(home.dest, cabin, name, x, ticket)) %>% 
#Convert to factor level
    mutate(pclass = factor(pclass, levels = c(1, 2, 3), labels = c('Upper', 'Middle', 'Lower')),
    survived = factor(survived, levels = c(0, 1), labels = c('No', 'Yes'))) %>%
na.omit()
#previously were characters
clean_titanic$age <- as.numeric(clean_titanic$age)
clean_titanic$fare <- as.numeric(clean_titanic$fare)
glimpse(clean_titanic)

create_train_test <- function(data, size = 0.8, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
data_train <- create_train_test(clean_titanic, 0.8, train = TRUE)
data_test <- create_train_test(clean_titanic, 0.8, train = FALSE)

```

#
Create a table reporting the proportion of people in the training set surviving the Titanic.  Do the same for the testing set.  Comment on whether the current training-testing partition looks suitable.  

```{r}
table(data_train$survived)
502/(502 + 332)


table(data_test$survived)
116/(116+93)

```

There is a slight discrepancy between the training and testing sets in terms of representation, but only by about 4.5%. There should be no major problem with the partition.

#
Use the `glm` command to build a logistic regression on the training partition.  `survived` should be your response variable and `pclass`, `sex`, `age`, `sibsp`, and `parch` should be your response variables.  

```{r}


titanicmod <- glm(survived~pclass+sex+age+sibsp+parch, data = data_train, family = binomial(link = "logit"))

summary(titanicmod)


```

We would now like to test whether this classifier is *fair* across the sex subgroups.  It was reported that women and children were prioritized on the life-boats and as a result survived the incident at a much higher rate.  Let us see if our model is able to capture this fact.  

#

Subset your test data into a male group and a female group.  Then, use the `predict` function on the male testing group to come up with predicted probabilities of surviving the Titanic for each male in the testing set.  Do the same for the female testing group.  

```{r}



maletest <- data_test |> 
  filter(sex == "male")


femaletest <- data_test |> 
  filter(sex == "female")


fittedmenvals <- predict(titanicmod, newdata = maletest, type = "response")


fittedwomenvals <- predict(titanicmod, newdata = femaletest, type = "response")

```

# 

Now recall that for this logistic *regression* to be a true classifier, we need to pair it with a decision boundary.  Use an `if-else` statement to translate any predicted probability in the male group greater than $0.5$ into `Yes` (as in Yes this individual is predicted to have survived).  Likewise an predicted probability less than $0.5$ should be translated into a `No`.  

Do this for the female testing group as well, and then create a confusion matrix for each of the male and female test set predictions.  You can use the `confusionMatrix` command as seen in class to expidite this process as well as provide you necessary metrics for the following questions.  

```{r}
library(caret)


fitted.men.results <- ifelse(fittedmenvals > 0.5, "Yes", "No")

fitted.women.results <- ifelse(fittedwomenvals > 0.5, "Yes", "No")

confusionMatrix(as.factor(fitted.men.results), maletest$survived, positive = "Yes")

confusionMatrix(as.factor(fitted.women.results), femaletest$survived, positive = "Yes")


```

#
We can see that indeed, at least within the testing groups, women did seem to survive at a higher proportion than men (24.8\% to 76.3\% in the testing set).  Print a summary of your trained model and interpret one of the fitted coefficients in light of the above disparity.  

```{r}
summary(titanicmod)
```

If the sex of the passenger is male, the log(Odds) response of survival decreases by -2.684206.


#

Now let's see if our model is *fair* across this explanatory variable.  Calculate five measures (as defined in class) in this question: the Overall accuracy rate ratio between females and males, the disparate impact between females and males, the statistical parity between females and males, and the predictive equality as well as equal opportunity between females and males (collectively these last two comprise equalized odds).  Set a reasonable $\epsilon$ each time and then comment on which (if any) of these five criteria are met.  


```{r}
#Student Input

#Overall accuracy ratio:
(4+59+4+93)/(4+59+4+93+15+2+4+28)


#Disparate impact:
#Men predicted correctly (taken from confusion matrix):
97/(97+32)


#Women predicted correctly:
63/(63+17)

#Ratio of Men correct rate over Women correct rate:
(97/(97+32))/(63/(63+17))

```

The total accuracy rate is 0.7655502, or about 76.555%. Our model is accurate for most cases, if not all, so this measure of fairness appears to be met. 

Given an allowed $\epsilon$ of 0.05, the difference between the rate of females classified correctly and males classified correctly is within the stated bounds. Thus, the model predicts both men and women with decent all-round accuracy and does not predict one group much better than the other.


```{r}
#Disparate impact:

#Women True Negative/ Predicted Negative
4/(4+2)

#Men True Negative / # Predicted Negative
93 / (93+28)


#Women True Positive / # Predicted Positive
59 / (59+15)

#Men True Positive / # Predicted Positive
4 / (4+4)
```

However, these values indicate that the model possesses potential blind spots for missing male survivors and female fatalities (0.6667 and 0.5 being far below the model average accuracy of 0.7656). This is still difficult to conclude based on our data because of the small amount of the sample who fit into these classifications. We might need to take a multitude of random samples to see if the true positive and true negative rates remain at these levels. 



```{r}
#Statistical parity

#Proportion of men predicted to survive
8/129

#Proportion of women predicted to survive
74/80
```

There is not statistical parity in our model, because predicting 6.2% of men and 92.5% of women to survive indicates a bias for all reasonable values of  $\epsilon$, even raising it from 0.1.


Given that the log(Odds) in the model summary is nonzero with a significant p-value, we have neither predictive equality nor equal opportunity between females and males.




It is always important for us to interpret our results in light of the original data and the context of the analysis.  In this case, it is relevant that we are analyzing a historical event post-facto and any disparities across demographics identified are unlikely to be replicated.  So even though our model fails numerous of the statistical fairness criteria, I would argue we need not worry that our model could be misused to perpetuate discrimination in the future.  After all, this model is likely not being used to prescribe a preferred method of treatment in the future.  


#

Even so, provide a *philosophical* notion of justice or fairness that may have motivated the Titanic survivors to act as they did. Spell out what this philosophical notion or principle entails?



Seeing that men appear to have died more frequently than women, the survivors of the Titanic might have adhered to an archaic verson of John Rawls' Difference Principle. This principle states that where differences exist, resources ought to be allocated to the most vulnerable. Traditionally, saving the women and children before the men was an act of chivalry, implying that men were expected to be less vulnerable and thus obliged to wait for others before making their own ways to safety. 

Clearly, many women are more physcially and mentally able than men, but in 1912 this logic met with more popularity. 

